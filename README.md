# ğŸ§  API de DÃ©tection de DÃ©pression avec LLM

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109.0-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Tests](https://img.shields.io/badge/Tests-Passing-brightgreen.svg)](tests/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](Dockerfile)

API REST professionnelle pour la dÃ©tection automatique de signes de dÃ©pression dans les textes, utilisant des Large Language Models (LLM).

**Projet acadÃ©mique - X5 Semestre 9 ETSIA**

> âš ï¸ **Avertissement** : Ce systÃ¨me est Ã  usage de RECHERCHE uniquement. Il ne remplace PAS un diagnostic mÃ©dical professionnel.

---

## ğŸ¯ RÃ©sultats

| ModÃ¨le | PrÃ©cision | Vitesse | Avantages |
|--------|-----------|---------|-----------|
| **LLM (GPT-4o-mini)** | **75%** | 0.3/s | Explications dÃ©taillÃ©es, cas ambigus |
| **LLM (Llama 3.2 local)** | **75%** | 0.3/s | Gratuit, privÃ©, offline |
| **LLM (Claude)** | **75%** | 0.3/s | Haute qualitÃ©, nuancÃ© |

### Performance par CatÃ©gorie

| CatÃ©gorie | PrÃ©cision |
|-----------|-----------|
| DÃ©pression claire | 80% |
| Normal clair | 100% |
| Textes courts | 40% |
| Cas ambigus | **80%** â­ |

---

## ğŸš€ DÃ©marrage Rapide

### Installation

```bash
# Cloner le projet
git clone <votre-repo>
cd ETSIA_ML_API

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env avec vos clÃ©s API
```

### Lancer l'API

```bash
# Mode dÃ©veloppement
uvicorn app.main:app --reload --port 8000

# Mode production
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Tester l'API

```bash
# Health check
curl http://localhost:8000/health

# PrÃ©diction simple
curl -X POST http://localhost:8000/api/v1/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "I feel so sad and hopeless"}'

# Documentation interactive
# Ouvrir http://localhost:8000/docs
```

---

## ğŸ“ Structure du Projet

```
ETSIA_ML_API/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                      # Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ config.py                    # Configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                        # â­ Infrastructure multi-modÃ¨les
â”‚   â”‚   â”œâ”€â”€ base_model.py           # Interface de base
â”‚   â”‚   â””â”€â”€ model_registry.py       # Registre des modÃ¨les
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py              # SchÃ©mas Pydantic
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                    # â­ ModÃ¨les de dÃ©tection
â”‚   â”‚   â”œâ”€â”€ yansnet_llm/            # ModÃ¨le LLM (YANSNET)
â”‚   â”‚   â”‚   â”œâ”€â”€ yansnet_llm_model.py
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_predictor.py
â”‚   â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ [autres_modeles]/       # ModÃ¨les des autres Ã©tudiants
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ api.py                  # Routes API (multi-modÃ¨les)
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logger.py               # Logging
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ API_CONTRACT.md             # Contrat d'API dÃ©taillÃ©
â”‚   â”œâ”€â”€ DATA_SOURCES.md             # Sources de donnÃ©es
â”‚   â”œâ”€â”€ DEPLOYMENT.md               # Guide de dÃ©ploiement
â”‚   â””â”€â”€ ADD_YOUR_MODEL.md           # â­ Guide pour ajouter un modÃ¨le
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py                 # Tests unitaires
â”‚
â”œâ”€â”€ .env.example                    # Template variables d'environnement
â”œâ”€â”€ requirements.txt                # DÃ©pendances Python
â””â”€â”€ README.md                       # Ce fichier
```

---

## ğŸ”§ Configuration

### Variables d'Environnement

CrÃ©er un fichier `.env` :

```env
# LLM Provider (gpt, claude, local)
LLM_PROVIDER=gpt

# OpenAI (si provider=gpt)
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini

# Anthropic (si provider=claude)
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Ollama (si provider=local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# API Configuration
API_TITLE=Depression Detection API
API_VERSION=1.0.0
LOG_LEVEL=INFO
```

### Configuration LLM Local (Ollama)

```bash
# Installer Ollama
# https://ollama.ai

# TÃ©lÃ©charger le modÃ¨le
ollama pull llama3.2

# Lancer le serveur
ollama serve

# Tester
curl http://localhost:11434/api/tags
```

---

## ğŸ“– Documentation API

### Endpoints Principaux

#### `GET /api/v1/models`
Liste tous les modÃ¨les disponibles.

**Response:**
```json
{
  "models": {
    "yansnet-llm": {
      "name": "yansnet-llm",
      "version": "1.0.0",
      "author": "Ã‰quipe YANSNET",
      "is_default": true
    }
  },
  "total": 1,
  "default": "yansnet-llm"
}
```

#### `POST /api/v1/predict`
Analyse un texte et dÃ©tecte les signes de dÃ©pression.

**Request:**
```json
{
  "text": "I feel so sad and hopeless",
  "include_reasoning": true
}
```

**Query Parameters:**
- `model_name` (optionnel) : Nom du modÃ¨le Ã  utiliser

**Response:**
```json
{
  "prediction": "DÃ‰PRESSION",
  "confidence": 0.85,
  "severity": "Ã‰levÃ©e",
  "reasoning": "Le texte exprime un dÃ©sespoir profond et une tristesse intense...",
  "timestamp": "2025-01-16T10:30:00Z",
  "model_used": "yansnet-llm"
}
```

#### `POST /api/v1/batch-predict`
Analyse plusieurs textes en batch.

**Request:**
```json
{
  "texts": [
    "I'm so happy today",
    "I feel worthless and empty"
  ]
}
```

**Response:**
```json
{
  "results": [
    {
      "text": "I'm so happy today",
      "prediction": "NORMAL",
      "confidence": 0.95
    },
    {
      "text": "I feel worthless and empty",
      "prediction": "DÃ‰PRESSION",
      "confidence": 0.88
    }
  ],
  "total_processed": 2,
  "processing_time": 1.2
}
```

Voir [API_CONTRACT.md](docs/API_CONTRACT.md) pour la documentation complÃ¨te.

---

## ğŸ“Š Sources de DonnÃ©es

### Datasets UtilisÃ©s pour Validation

1. **Combined Data** (53,043 textes)
   - 7 classes : Normal, Depression, Suicidal, Anxiety, Bipolar, Stress, Personality disorder
   - Source : Compilation de datasets publics Reddit/Twitter

2. **CLPsych Shared Task** (1,800 utilisateurs)
   - 3 conditions : Depression vs Control, PTSD vs Control, PTSD vs Depression
   - Source : CLPsych 2015 Shared Task

Voir [DATA_SOURCES.md](docs/DATA_SOURCES.md) pour plus de dÃ©tails.

---

## ğŸ“ Ajouter Votre Propre ModÃ¨le

L'API utilise une **architecture multi-modÃ¨les** qui permet Ã  chaque Ã©tudiant d'ajouter son propre modÃ¨le sans conflit.

### Ã‰tapes Rapides

1. **CrÃ©er votre dossier** : `app/services/votre_nom_modele/`
2. **ImplÃ©menter l'interface** : HÃ©riter de `BaseDepressionModel`
3. **Enregistrer** : Ajouter dans `app/main.py`
4. **Tester** : `curl http://localhost:8000/api/v1/models`

Voir le guide complet : [docs/ADD_YOUR_MODEL.md](docs/ADD_YOUR_MODEL.md)

---

## ğŸ§ª Tests

```bash
# Lancer tous les tests
pytest tests/ -v

# Tests avec couverture
pytest tests/ --cov=app --cov-report=html

# Test d'un endpoint spÃ©cifique
pytest tests/test_api.py::test_predict_endpoint -v
```

---

## ğŸš¢ DÃ©ploiement

### Docker

```bash
# Build
docker build -t depression-detection-api .

# Run
docker run -p 8000:8000 --env-file .env depression-detection-api
```

### Cloud (Render, Railway, etc.)

Voir [DEPLOYMENT.md](docs/DEPLOYMENT.md) pour les guides dÃ©taillÃ©s.

---

## âš ï¸ Avertissement Important

**Ce systÃ¨me est Ã  usage de RECHERCHE uniquement.**

- âŒ Ne remplace PAS un diagnostic mÃ©dical professionnel
- âŒ Ne pas utiliser pour des dÃ©cisions mÃ©dicales
- âœ… Utiliser uniquement pour la recherche acadÃ©mique
- âœ… Toujours consulter un professionnel de santÃ©

### Ressources d'Aide

Si vous ou quelqu'un que vous connaissez Ãªtes en dÃ©tresse :
- **France** : SOS AmitiÃ© (09 72 39 40 50), 3114 (prÃ©vention suicide)
- **International** : https://www.iasp.info/resources/Crisis_Centres/

---

## ğŸ“ˆ Performances et CoÃ»ts

### Latence
- GPT-4o-mini : ~300ms par requÃªte
- Claude : ~300ms par requÃªte
- Llama local : ~300ms par requÃªte (dÃ©pend du hardware)

### CoÃ»ts (GPT-4o-mini)
- Input : $0.150 / 1M tokens (~$0.00001 par texte)
- Output : $0.600 / 1M tokens (~$0.00005 par texte)
- **Total : ~$0.00006 par prÃ©diction** (nÃ©gligeable)

### Recommandations
- **Production** : GPT-4o-mini (meilleur rapport qualitÃ©/prix)
- **DÃ©veloppement** : Llama local (gratuit, privÃ©)
- **Haute qualitÃ©** : Claude (meilleure nuance)

---

## ğŸ› ï¸ Technologies

- **Framework** : FastAPI 0.109.0
- **LLM** : OpenAI GPT-4o-mini / Anthropic Claude / Ollama Llama
- **Validation** : Pydantic 2.5.0
- **Logging** : Python logging + structlog
- **Tests** : Pytest 7.4.0

---

## ğŸ“ Licence

Projet acadÃ©mique - X5 Semestre 9 ETSIA, 2025

---

## ğŸ‘¥ Auteurs

Ã‰quipe YANSNET - ETSIA

---

## ğŸ“§ Contact

Pour toute question sur ce projet acadÃ©mique, contactez l'Ã©quipe YANSNET.

---

**DerniÃ¨re mise Ã  jour** : Janvier 2025
