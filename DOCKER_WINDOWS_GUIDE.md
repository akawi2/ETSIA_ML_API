# üê≥ Guide Docker pour Windows - ETSIA ML API

## üéØ **Syst√®me Unifi√©**

Le projet utilise maintenant **un seul Dockerfile** intelligent qui s'adapte automatiquement au CPU ou GPU selon vos besoins.

## üöÄ **D√©ploiement Rapide**

### **Option 1: CPU (Recommand√© pour d√©buter)**
```powershell
.\docker-deploy.ps1 cpu
```
- **Port**: 8000
- **URL**: http://localhost:8000
- **Documentation**: http://localhost:8000/docs

### **Option 2: GPU (Performance maximale)**
```powershell
.\docker-deploy.ps1 gpu
```
- **Port**: 8001  
- **URL**: http://localhost:8001
- **Documentation**: http://localhost:8001/docs
- **Pr√©requis**: NVIDIA GPU + Docker GPU support

## üõ†Ô∏è **Commandes Disponibles**

### **D√©ploiement**
```powershell
# CPU uniquement (d√©faut)
.\docker-deploy.ps1 cpu

# GPU avec CUDA
.\docker-deploy.ps1 gpu
```

### **Gestion**
```powershell
# Arr√™ter tous les services
.\docker-deploy.ps1 stop

# Voir les logs en temps r√©el
.\docker-deploy.ps1 logs

# V√©rifier la sant√© de l'API
.\docker-deploy.ps1 health

# Nettoyage complet
.\docker-deploy.ps1 clean

# Aide
.\docker-deploy.ps1 help
```

## üîß **Architecture Technique**

### **Dockerfile Unifi√©**
```dockerfile
# Utilise une image de base variable
ARG BASE_IMAGE=python:3.11-slim
FROM ${BASE_IMAGE}

# S'adapte automatiquement √† CPU ou GPU
```

### **Images G√©n√©r√©es**
- **CPU**: `etsia-ml-api:cpu` (bas√©e sur python:3.11-slim)
- **GPU**: `etsia-ml-api:gpu` (bas√©e sur nvidia/cuda:12.1-runtime)

### **Conteneurs Cr√©√©s**
- **CPU**: `etsia-ml-api-cpu` sur port 8000
- **GPU**: `etsia-ml-api-gpu` sur port 8001

## üéØ **Avantages du Nouveau Syst√®me**

### ‚úÖ **Simplicit√©**
- **1 seul Dockerfile** au lieu de 2
- **1 seul script** PowerShell optimis√© pour Windows
- **D√©tection automatique** des capacit√©s

### ‚úÖ **Flexibilit√©**
- **Basculement facile** entre CPU et GPU
- **Coexistence possible** des deux modes
- **Configuration par variables d'environnement**

### ‚úÖ **Maintenance**
- **Code unifi√©** plus facile √† maintenir
- **Moins de duplication**
- **√âvolution centralis√©e**

## üîç **V√©rification du D√©ploiement**

### **Test Automatique**
Le script v√©rifie automatiquement la sant√© apr√®s d√©ploiement :
```
‚úÖ API CPU: Healthy
‚úÖ API GPU: Healthy
```

### **Test Manuel**
```powershell
# Tester l'endpoint de sant√©
curl http://localhost:8000/health

# Tester une pr√©diction
curl -X POST http://localhost:8000/api/v1/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "Je me sens triste"}'
```

## üö® **Pr√©requis GPU**

Pour utiliser le mode GPU, assurez-vous d'avoir :

1. **GPU NVIDIA** compatible CUDA
2. **Pilotes NVIDIA** r√©cents
3. **NVIDIA Docker Runtime** install√©
4. **Docker Desktop** avec support GPU activ√©

### **Installation NVIDIA Docker (Windows)**
```powershell
# Installer NVIDIA Container Toolkit
# Suivre: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html
```

## üìä **Comparaison des Performances**

| Mode | Mod√®les Support√©s | Performance | M√©moire |
|------|------------------|-------------|---------|
| CPU  | Tous | Standard | ~2GB |
| GPU  | Tous + Acc√©l√©ration | 3-10x plus rapide | ~4-8GB |

## üîß **D√©pannage**

### **Erreur "Docker non install√©"**
```powershell
# Installer Docker Desktop pour Windows
# https://docs.docker.com/desktop/windows/install/
```

### **Erreur GPU non disponible**
```powershell
# V√©rifier le support GPU
docker run --rm --gpus all nvidia/cuda:12.1-base-ubuntu22.04 nvidia-smi
```

### **Port d√©j√† utilis√©**
```powershell
# Arr√™ter les services existants
.\docker-deploy.ps1 stop

# Ou changer le port dans le script
```

## üìö **Ressources**

- **Documentation API**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health
- **Mod√®les disponibles**: http://localhost:8000/api/v1/models
- **Logs**: `.\docker-deploy.ps1 logs`

---

**üéâ Votre API ETSIA ML est maintenant optimis√©e pour Windows avec un syst√®me Docker unifi√© !**
