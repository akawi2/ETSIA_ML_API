# üñºÔ∏è Guide d'Utilisation - Analyse d'Images

Guide complet pour utiliser le mod√®le de d√©tection de contenu sensible dans les images.

---

## üéØ Vue d'Ensemble

Le mod√®le **SensitiveImageCaptionModel** analyse les images pour d√©tecter du contenu sensible :
- üö´ **Drogue** et substances ill√©gales
- üî´ **Violence** et armes
- üîû **Contenu sexuel**
- üí£ **Autres contenus probl√©matiques**

**Processus :**
1. G√©n√®re une l√©gende de l'image (microsoft/git-large-textcaps)
2. D√©tecte les mots-cl√©s sensibles
3. Traduit en fran√ßais
4. Retourne une alerte si contenu d√©tect√©

---

## üì¶ Installation

### 1. Installer les D√©pendances

```bash
# D√©pendances principales (d√©j√† install√©es)
pip install -r requirements.txt

# D√©pendances sp√©cifiques au mod√®le d'images
pip install -r app/services/sensitive_image_caption/requirements.txt
```

**Packages requis :**
- `transformers>=4.30.0`
- `torch>=2.0.0`
- `Pillow>=9.5.0`
- `sentencepiece>=0.1.99`

### 2. T√©l√©charger les Mod√®les (Optionnel)

Les mod√®les se t√©l√©chargent automatiquement au premier lancement. Pour pr√©-t√©l√©charger :

```python
from transformers import GitProcessor, GitForCausalLM, pipeline

# Mod√®le de g√©n√©ration de l√©gendes
GitProcessor.from_pretrained("microsoft/git-large-textcaps")
GitForCausalLM.from_pretrained("microsoft/git-large-textcaps")

# Mod√®le de traduction
pipeline("translation", model="Helsinki-NLP/opus-mt-en-fr")
```

---

## üöÄ Utilisation

### Via l'API REST

#### **1. Analyser une Image Unique**

```bash
# Avec curl
curl -X POST "http://localhost:8000/api/v1/predict-image" \
  -H "Content-Type: multipart/form-data" \
  -F "image=@path/to/image.jpg"
```

**R√©ponse :**
```json
{
  "prediction": "S√õR",
  "confidence": 0.95,
  "severity": "Aucune",
  "reasoning": "‚úÖ Contenu s√ªr - Aucun √©l√©ment sensible d√©tect√©",
  "caption_en": "a cat sitting on a table",
  "caption_fr": "un chat assis sur une table",
  "is_safe": true,
  "model_used": "sensitive-image-caption"
}
```

#### **2. Avec Python requests**

```python
import requests

# Analyser une image
with open("image.jpg", "rb") as f:
    response = requests.post(
        "http://localhost:8000/api/v1/predict-image",
        files={"image": f}
    )

result = response.json()
print(f"Pr√©diction: {result['prediction']}")
print(f"S√ªr: {result['is_safe']}")
print(f"L√©gende FR: {result['caption_fr']}")
```

#### **3. Analyser Plusieurs Images (Batch)**

```python
import requests

# Pr√©parer les images
files = [
    ("images", open("image1.jpg", "rb")),
    ("images", open("image2.jpg", "rb")),
    ("images", open("image3.jpg", "rb"))
]

# Envoyer
response = requests.post(
    "http://localhost:8000/api/v1/batch-predict-images",
    files=files
)

result = response.json()
print(f"Trait√©: {result['total_processed']} images")

for i, res in enumerate(result['results']):
    print(f"\nImage {i+1}:")
    print(f"  Pr√©diction: {res['prediction']}")
    print(f"  L√©gende: {res['caption_fr']}")
```

### Utilisation Directe (Python)

#### **1. Import et Initialisation**

```python
from app.services.sensitive_image_caption import SensitiveImageCaptionModel
from PIL import Image

# Initialiser le mod√®le
model = SensitiveImageCaptionModel()
```

#### **2. Analyser une Image**

```python
# Charger l'image
image = Image.open("path/to/image.jpg")

# Pr√©dire
result = model.predict(image=image)

# Afficher les r√©sultats
print(f"Pr√©diction: {result['prediction']}")
print(f"Confiance: {result['confidence']:.2%}")
print(f"S√ªr: {result['is_safe']}")
print(f"L√©gende EN: {result['caption_en']}")
print(f"L√©gende FR: {result['caption_fr']}")
print(f"Explication: {result['reasoning']}")
```

#### **3. Analyser Plusieurs Images**

```python
from PIL import Image

# Charger les images
images = [
    Image.open("image1.jpg"),
    Image.open("image2.jpg"),
    Image.open("image3.jpg")
]

# Pr√©dire en batch
results = model.batch_predict(images=images)

# Afficher
for i, result in enumerate(results):
    print(f"\nImage {i+1}:")
    print(f"  Pr√©diction: {result['prediction']}")
    print(f"  L√©gende FR: {result['caption_fr']}")
    print(f"  S√ªr: {result['is_safe']}")
```

---

## üìä Exemples de R√©sultats

### Image S√ªre (Chat)

**Input :** `cat.jpg`

**Output :**
```json
{
  "prediction": "S√õR",
  "confidence": 0.95,
  "severity": "Aucune",
  "reasoning": "‚úÖ Contenu s√ªr - Aucun √©l√©ment sensible d√©tect√©",
  "caption_en": "a cat sitting on a table",
  "caption_fr": "un chat assis sur une table",
  "is_safe": true
}
```

### Image Sensible (D√©tection de drogue)

**Input :** `sensitive.jpg`

**Output :**
```json
{
  "prediction": "SENSIBLE",
  "confidence": 0.85,
  "severity": "√âlev√©e",
  "reasoning": "‚ö†Ô∏è CONTENU SENSIBLE D√âTECT√â - Cette image contient un contenu inappropri√©",
  "caption_en": "a *** on a table",
  "caption_fr": "une *** sur une table",
  "is_safe": false
}
```

---

## üîç Mots-cl√©s D√©tect√©s

### Cat√©gories

| Cat√©gorie | Exemples EN | Exemples FR |
|-----------|-------------|-------------|
| **Drogue** | drugs, cocaine, heroin, marijuana, weed | drogue, coca√Øne, h√©ro√Øne |
| **Violence** | gun, weapon, knife, blood, kill | arme, couteau, sang, tuer |
| **Sexe** | porn, nude, naked, sexual | pornographie, nudit√©, sexuel |
| **Autres** | bomb, explosive, suicide | bombe, explosif, suicide |

### Liste Compl√®te

Voir `SENSITIVE_KEYWORDS` dans le code source.

---

## üß™ Tests

### Lancer les Tests

```bash
# Tous les tests du mod√®le
pytest tests/test_image_model.py -v

# Tests unitaires uniquement
pytest tests/test_image_model.py -k "test_model" -v

# Tests d'int√©gration API
pytest tests/test_image_model.py -k "test_predict" -v

# Tests de performance (plus lents)
pytest tests/test_image_model.py -k "test_performance" -v
```

### Cr√©er vos Propres Tests

```python
import pytest
from app.services.sensitive_image_caption import SensitiveImageCaptionModel
from PIL import Image

def test_custom_image():
    """Test avec votre image"""
    model = SensitiveImageCaptionModel()
    
    # Votre image
    image = Image.open("my_image.jpg")
    
    # Pr√©dire
    result = model.predict(image=image)
    
    # V√©rifier
    assert result["prediction"] in ["SENSIBLE", "S√õR"]
    assert 0 <= result["confidence"] <= 1
    assert "caption_fr" in result
```

---

## ‚öôÔ∏è Configuration Avanc√©e

### Utiliser GPU

```python
import torch

# V√©rifier si GPU disponible
print(f"CUDA disponible: {torch.cuda.is_available()}")

# Le mod√®le utilise automatiquement le GPU si disponible
model = SensitiveImageCaptionModel()
print(f"Device: {model.device}")  # "cuda" ou "cpu"
```

### Forcer CPU

```python
import os

# D√©sactiver CUDA
os.environ["CUDA_VISIBLE_DEVICES"] = ""

# Initialiser le mod√®le
model = SensitiveImageCaptionModel()
```

### Personnaliser les Mots-cl√©s

```python
# Ajouter des mots-cl√©s personnalis√©s
model = SensitiveImageCaptionModel()

# Ajouter
model.SENSITIVE_KEYWORDS.update({
    'nouveau_mot',
    'autre_mot'
})

# Retirer
model.SENSITIVE_KEYWORDS.discard('mot_existant')
```

---

## üìà Performances

### Temps de Traitement

| Configuration | Temps/Image |
|---------------|-------------|
| GPU (CUDA) | 2-3 secondes |
| CPU | 10-15 secondes |

### Optimisation

```python
# Pour traiter beaucoup d'images
images = [Image.open(f"img{i}.jpg") for i in range(100)]

# Traiter par batch de 5
batch_size = 5
for i in range(0, len(images), batch_size):
    batch = images[i:i+batch_size]
    results = model.batch_predict(images=batch)
```

---

## ‚ö†Ô∏è Limitations

1. **D√©pend de la qualit√© des l√©gendes**
   - Le mod√®le g√©n√®re d'abord une l√©gende textuelle
   - Si la l√©gende est impr√©cise, la d√©tection peut √©chouer

2. **Mots-cl√©s limit√©s**
   - D√©tection bas√©e sur une liste de mots-cl√©s
   - Peut manquer certains contenus subtils

3. **Contexte**
   - Ne comprend pas le contexte
   - Ex: "water gun" sera d√©tect√© comme "gun"

4. **Langues**
   - Optimis√© pour anglais et fran√ßais
   - Autres langues non support√©es

---

## üîß D√©pannage

### Erreur : "Out of Memory"

**Solution :** R√©duire la taille du batch ou utiliser CPU

```python
# Traiter une image √† la fois
for image in images:
    result = model.predict(image=image)
```

### Erreur : "Model not found"

**Solution :** T√©l√©charger manuellement les mod√®les

```bash
python -c "from transformers import GitProcessor, GitForCausalLM; \
  GitProcessor.from_pretrained('microsoft/git-large-textcaps'); \
  GitForCausalLM.from_pretrained('microsoft/git-large-textcaps')"
```

### Performance Lente

**Solutions :**
1. Utiliser un GPU
2. R√©duire la taille des images
3. Utiliser un mod√®le plus petit

---

## üìö Ressources

- [microsoft/git-large-textcaps](https://huggingface.co/microsoft/git-large-textcaps)
- [Helsinki-NLP/opus-mt-en-fr](https://huggingface.co/Helsinki-NLP/opus-mt-en-fr)
- [Documentation Transformers](https://huggingface.co/docs/transformers)

---

## ü§ù Contribution

Pour am√©liorer le mod√®le :

1. Ajouter des mots-cl√©s dans `SENSITIVE_KEYWORDS`
2. Am√©liorer la d√©tection (ML au lieu de r√®gles)
3. Support de nouvelles langues
4. Optimiser les performances

---

**Version:** 1.0.0  
**Derni√®re mise √† jour:** Octobre 2025
