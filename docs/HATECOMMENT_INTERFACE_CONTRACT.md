# üìã Contrat d'Interface - Mod√®le HateComment BERT

## üìñ Vue d'Ensemble

Ce document d√©finit le contrat d'interface pour le mod√®le `hatecomment-bert`, un mod√®le de d√©tection de hate speech int√©gr√© dans l'API ETSIA_ML_API. Le mod√®le respecte l'interface `BaseDepressionModel` tout en fournissant des fonctionnalit√©s sp√©cialis√©es pour la d√©tection de discours haineux.

---

## üèóÔ∏è Architecture du Mod√®le

### **Classe Principale**
```python
class HateCommentBertModel(BaseDepressionModel)
```

### **Mod√®le de Base**
- **Architecture** : BERT multilingue (`bert-base-multilingual-cased`)
- **Type** : Classification binaire de s√©quences
- **Langues support√©es** : Fran√ßais, Anglais (extensible)
- **Framework** : PyTorch + Transformers

---

## üìù Propri√©t√©s Obligatoires

### **M√©tadonn√©es du Mod√®le**

| Propri√©t√© | Type | Valeur | Description |
|-----------|------|--------|-------------|
| `model_name` | `str` | `"hatecomment-bert"` | Identifiant unique du mod√®le |
| `model_version` | `str` | `"1.0.0"` | Version s√©mantique |
| `author` | `str` | `"√âquipe ETSIA"` | Auteur/Organisation |
| `description` | `str` | `"BERT multilingue fine-tun√© pour d√©tection de hate speech"` | Description courte |
| `tags` | `List[str]` | `["bert", "multilingual", "hate-speech", "french", "english", "transformers"]` | Tags de classification |

### **Exemple d'Impl√©mentation**
```python
@property
def model_name(self) -> str:
    return "hatecomment-bert"

@property
def model_version(self) -> str:
    return "1.0.0"

@property
def author(self) -> str:
    return "√âquipe ETSIA"
```

---

## üîß M√©thodes Obligatoires

### **1. M√©thode `predict()`**

#### **Signature**
```python
def predict(self, text: str, **kwargs) -> Dict[str, Any]
```

#### **Param√®tres d'Entr√©e**
| Param√®tre | Type | Obligatoire | Description |
|-----------|------|-------------|-------------|
| `text` | `str` | ‚úÖ | Texte √† analyser (1-5000 caract√®res) |
| `**kwargs` | `Any` | ‚ùå | Param√®tres additionnels (ignor√©s) |

#### **Format de Sortie**
```python
{
    "prediction": str,           # "HAINEUX" ou "NON-HAINEUX"
    "confidence": float,         # 0.0 √† 1.0
    "severity": str,            # "Aucune", "Faible", "Moyenne", "√âlev√©e", "Critique"
    "reasoning": str,           # Explication d√©taill√©e
    "hate_classification": str, # "haineux" ou "non-haineux"
    "original_label": str,      # "LABEL_1" ou "LABEL_0"
    "model_fine_tuned": bool    # True si mod√®le fine-tun√© utilis√©
}
```

#### **Exemple de R√©ponse**
```json
{
    "prediction": "HAINEUX",
    "confidence": 0.92,
    "severity": "Critique",
    "reasoning": "Commentaire classifi√© comme haineux avec une confiance de 92.00%. Le contenu contient des √©l√©ments de discours haineux.",
    "hate_classification": "haineux",
    "original_label": "LABEL_1",
    "model_fine_tuned": false
}
```

### **2. M√©thode `batch_predict()`**

#### **Signature**
```python
def batch_predict(self, texts: List[str], **kwargs) -> List[Dict[str, Any]]
```

#### **Param√®tres d'Entr√©e**
| Param√®tre | Type | Obligatoire | Description |
|-----------|------|-------------|-------------|
| `texts` | `List[str]` | ‚úÖ | Liste de textes (max 100) |
| `**kwargs` | `Any` | ‚ùå | Param√®tres additionnels |

#### **Format de Sortie**
```python
[
    {
        "prediction": "HAINEUX",
        "confidence": 0.85,
        "severity": "√âlev√©e",
        "reasoning": "...",
        # ... autres champs
    },
    # ... autres r√©sultats
]
```

### **3. M√©thode `health_check()`**

#### **Signature**
```python
def health_check(self) -> Dict[str, Any]
```

#### **Format de Sortie**
```python
{
    "status": str,              # "healthy" ou "unhealthy"
    "model": str,               # "hatecomment-bert"
    "version": str,             # "1.0.0"
    "device": str,              # "cuda:0" ou "cpu"
    "fine_tuned": bool,         # √âtat du fine-tuning
    "test_prediction": str,     # R√©sultat d'un test simple
    # Si GPU disponible :
    "gpu_name": str,            # Nom du GPU
    "gpu_memory_allocated": str, # M√©moire allou√©e
    "gpu_memory_cached": str,   # M√©moire en cache
    "gpu_utilization": str      # √âtat d'utilisation
}
```

---

## üéØ Logique de Classification

### **Mapping des Labels**

#### **Labels Internes ‚Üí API**
| Label Interne | Pr√©diction API | Description |
|---------------|----------------|-------------|
| `LABEL_1` | `"HAINEUX"` | Contenu haineux d√©tect√© |
| `LABEL_0` | `"NON-HAINEUX"` | Contenu non-haineux |

#### **Niveaux de S√©v√©rit√©**
| Confiance | S√©v√©rit√© | Description |
|-----------|----------|-------------|
| > 90% | `"Critique"` | Tr√®s haute confiance |
| 80-90% | `"√âlev√©e"` | Haute confiance |
| 60-80% | `"Moyenne"` | Confiance mod√©r√©e |
| < 60% | `"Faible"` | Faible confiance |
| Non-haineux | `"Aucune"` | Pas de hate speech |

### **Pr√©traitement du Texte**

#### **√âtapes de Nettoyage**
1. **Suppression des espaces** en d√©but/fin
2. **Limitation de longueur** √† 500 caract√®res
3. **R√©duction des caract√®res r√©p√©t√©s** (ex: "haaaate" ‚Üí "haate")
4. **Normalisation des espaces** multiples
5. **Suppression des caract√®res de contr√¥le**

#### **Gestion des Cas Limites**
| Cas | Comportement |
|-----|--------------|
| Texte vide | Retourne `"NON-HAINEUX"` avec confiance 0.5 |
| Texte trop long | Tronqu√© √† 500 caract√®res |
| Erreur de traitement | Retourne `"ERREUR"` avec d√©tails |

---

## üîå Int√©gration API

### **Routes Automatiques**

Le mod√®le est automatiquement expos√© via les routes suivantes :

#### **1. Pr√©diction Simple**
```http
POST /api/v1/predict?model_name=hatecomment-bert
Content-Type: application/json

{
    "text": "Je d√©teste tout le monde",
    "include_reasoning": true
}
```

#### **2. Pr√©diction Batch**
```http
POST /api/v1/batch-predict?model_name=hatecomment-bert
Content-Type: application/json

{
    "texts": [
        "Hello world",
        "I hate everyone"
    ],
    "include_reasoning": false
}
```

#### **3. Health Check**
```http
GET /api/v1/models/hatecomment-bert/health
```

#### **4. Liste des Mod√®les**
```http
GET /api/v1/models
```

### **Sch√©mas de Validation**

#### **Valeurs Accept√©es**
```python
class PredictionEnum(str, Enum):
    DEPRESSION = "D√âPRESSION"      # Mod√®les de d√©pression
    NORMAL = "NORMAL"              # √âtat normal
    ERROR = "ERREUR"               # Erreur de traitement
    HATEFUL = "HAINEUX"            # ‚úÖ Hate speech d√©tect√©
    NON_HATEFUL = "NON-HAINEUX"    # ‚úÖ Pas de hate speech
```

---

## ‚öôÔ∏è Configuration et Optimisations

### **Device Management**
```python
# D√©tection automatique du device
self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Optimisations GPU
if self.device.type == "cuda":
    torch.cuda.empty_cache()
    torch.backends.cudnn.benchmark = True
```

### **Pipeline de Classification**
```python
self.classifier = pipeline(
    "text-classification",
    model=self.model,
    tokenizer=self.tokenizer,
    device=0 if self.device.type == "cuda" else -1,
    return_all_scores=True
)
```

### **Gestion des Mod√®les Fine-tun√©s**
```python
# Chargement conditionnel
if model_path and self._model_exists(model_path):
    # Mod√®le fine-tun√© personnalis√©
    self.model = AutoModelForSequenceClassification.from_pretrained(
        model_path, num_labels=2
    )
    self.is_fine_tuned = True
else:
    # Mod√®le de base
    self.model = AutoModelForSequenceClassification.from_pretrained(
        'bert-base-multilingual-cased', num_labels=2
    )
    self.is_fine_tuned = False
```

---

## üß™ Tests et Validation

### **Tests Unitaires Requis**

#### **1. Test d'Initialisation**
```python
def test_model_initialization():
    model = HateCommentBertModel()
    assert model.model_name == "hatecomment-bert"
    assert model.model_version == "1.0.0"
    assert "hate-speech" in model.tags
```

#### **2. Test de Pr√©diction**
```python
def test_predict_basic():
    model = HateCommentBertModel()
    result = model.predict("Test message")
    
    assert "prediction" in result
    assert result["prediction"] in ["HAINEUX", "NON-HAINEUX", "ERREUR"]
    assert 0 <= result["confidence"] <= 1
```

#### **3. Test Health Check**
```python
def test_health_check():
    model = HateCommentBertModel()
    health = model.health_check()
    
    assert health["status"] in ["healthy", "unhealthy"]
    assert health["model"] == "hatecomment-bert"
```

### **Crit√®res de Performance**

| M√©trique | Seuil Minimum | Objectif |
|----------|---------------|----------|
| Temps de r√©ponse | < 2s par pr√©diction | < 1s |
| M√©moire GPU | < 2GB | < 1GB |
| Accuracy | > 75% | > 80% |
| F1-Score | > 70% | > 75% |

---

## üö® Gestion d'Erreurs

### **Types d'Erreurs**

#### **1. Erreurs d'Initialisation**
```python
# Mod√®le non initialis√©
if not self._initialized:
    raise RuntimeError(f"{self.model_name} n'est pas initialis√© correctement")
```

#### **2. Erreurs de Pr√©diction**
```python
# Retour gracieux en cas d'erreur
return {
    "prediction": "ERREUR",
    "confidence": 0.0,
    "severity": "Aucune",
    "reasoning": f"Erreur lors de l'analyse: {str(e)}"
}
```

### **Logging**
```python
# Utilisation du logger uniforme
from app.utils.logger import setup_logger
logger = setup_logger(__name__)

# Messages standardis√©s
logger.info(f"‚úì {self.model_name} initialis√© avec succ√®s")
logger.error(f"‚úó Erreur de pr√©diction {self.model_name}: {e}")
```

---

## üìä M√©triques et Monitoring

### **M√©triques Expos√©es**
- **Temps de traitement** par pr√©diction
- **Utilisation m√©moire** GPU/CPU
- **Taux de succ√®s** des pr√©dictions
- **Distribution des pr√©dictions** (haineux vs non-haineux)

### **Health Check D√©taill√©**
```python
{
    "status": "healthy",
    "model": "hatecomment-bert",
    "version": "1.0.0",
    "device": "cuda:0",
    "fine_tuned": false,
    "test_prediction": "NON-HAINEUX",
    "gpu_name": "NVIDIA GeForce RTX 4050",
    "gpu_memory_allocated": "245.2 MB",
    "gpu_memory_cached": "512.0 MB",
    "gpu_utilization": "Available"
}
```

---

## üîÑ √âvolutions Futures

### **Am√©liorations Pr√©vues**
1. **Support multilingue √©tendu** (espagnol, allemand, italien)
2. **Fine-tuning personnalis√©** sur donn√©es sp√©cifiques
3. **D√©tection de nuances** (ironie, sarcasme)
4. **Analyse contextuelle** (conversations compl√®tes)

### **R√©trocompatibilit√©**
- ‚úÖ **Interface stable** : Pas de breaking changes
- ‚úÖ **Versioning s√©mantique** : Incr√©ments de version appropri√©s
- ‚úÖ **Migration guid√©e** : Documentation des changements

---

## üìö R√©f√©rences

- **Mod√®le de base** : [BERT Multilingual](https://huggingface.co/bert-base-multilingual-cased)
- **Framework** : [Transformers](https://huggingface.co/transformers/)
- **Interface** : `BaseDepressionModel` (voir `app/core/base_model.py`)
- **Tests** : `tests/test_hatecomment_bert.py`

---

**Version du document** : 1.0.0  
**Derni√®re mise √† jour** : 20 octobre 2025  
**Auteur** : √âquipe ETSIA
