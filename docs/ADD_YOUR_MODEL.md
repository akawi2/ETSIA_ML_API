# ðŸŽ“ Guide : Ajouter Votre ModÃ¨le

Guide complet pour les Ã©tudiants qui veulent ajouter leur propre modÃ¨le de dÃ©tection de dÃ©pression.

---

## ðŸ“‹ Vue d'Ensemble

L'API utilise une **architecture multi-modÃ¨les** qui permet Ã  chaque Ã©tudiant d'ajouter son propre modÃ¨le sans conflit avec les autres.

### Principe

Chaque modÃ¨le est dans son propre dossier :
```
app/services/
â”œâ”€â”€ yansnet_llm/          # ModÃ¨le de l'Ã©quipe YANSNET
â”œâ”€â”€ votre_modele/         # VOTRE modÃ¨le ici
â””â”€â”€ autre_etudiant/       # ModÃ¨le d'un autre Ã©tudiant
```

---

## ðŸš€ Ã‰tapes pour Ajouter Votre ModÃ¨le

### 1. CrÃ©er la Structure

```bash
# CrÃ©er votre dossier
mkdir app/services/votre_nom_modele

# CrÃ©er les fichiers nÃ©cessaires
touch app/services/votre_nom_modele/__init__.py
touch app/services/votre_nom_modele/votre_nom_model.py
touch app/services/votre_nom_modele/requirements.txt
```

### 2. ImplÃ©menter l'Interface

CrÃ©er `app/services/votre_nom_modele/votre_nom_model.py` :

```python
"""
Votre modÃ¨le de dÃ©tection de dÃ©pression
"""
from typing import Dict, Any, List
from app.core.base_model import BaseMLModel
from app.utils.logger import setup_logger

logger = setup_logger(__name__)


class VotreNomModel(BaseMLModel):
    """
    Description de votre modÃ¨le.
    
    Exemple: ModÃ¨le GCN avec embeddings BERT
    """
    
    # ========================================================================
    # PROPRIÃ‰TÃ‰S OBLIGATOIRES
    # ========================================================================
    
    @property
    def model_name(self) -> str:
        """Nom unique (format: nom_equipe-type)"""
        return "votre_nom-gcn"  # Exemple: "dupont-gcn", "martin-lstm"
    
    @property
    def model_version(self) -> str:
        """Version du modÃ¨le"""
        return "1.0.0"
    
    @property
    def author(self) -> str:
        """Votre nom ou Ã©quipe"""
        return "Votre Nom"
    
    @property
    def description(self) -> str:
        """Description courte"""
        return "ModÃ¨le GCN avec embeddings BERT pour dÃ©tection de dÃ©pression"
    
    @property
    def tags(self) -> List[str]:
        """Tags pour catÃ©goriser"""
        return ["gcn", "bert", "graph-neural-network"]
    
    # ========================================================================
    # INITIALISATION
    # ========================================================================
    
    def __init__(self):
        """
        Initialisez votre modÃ¨le ici.
        
        Chargez les poids, configurez les paramÃ¨tres, etc.
        """
        try:
            # Exemple: charger un modÃ¨le PyTorch
            # self.model = torch.load('path/to/model.pt')
            # self.tokenizer = AutoTokenizer.from_pretrained('bert-base')
            
            logger.info(f"âœ“ {self.model_name} initialisÃ©")
            self._initialized = True
            
        except Exception as e:
            logger.error(f"âœ— Erreur d'initialisation: {e}")
            self._initialized = False
            raise
    
    # ========================================================================
    # MÃ‰THODE OBLIGATOIRE: PREDICT
    # ========================================================================
    
    def predict(self, text: str, **kwargs) -> Dict[str, Any]:
        """
        PrÃ©dit si le texte indique de la dÃ©pression.
        
        Args:
            text: Texte Ã  analyser
            **kwargs: ParamÃ¨tres additionnels (optionnels)
        
        Returns:
            Dict avec AU MINIMUM:
            {
                "prediction": "DÃ‰PRESSION" ou "NORMAL",
                "confidence": float (0.0 Ã  1.0),
                "severity": "Aucune"|"Faible"|"Moyenne"|"Ã‰levÃ©e"|"Critique",
                "reasoning": str (optionnel)
            }
        """
        if not self._initialized:
            raise RuntimeError(f"{self.model_name} non initialisÃ©")
        
        try:
            # VOTRE CODE ICI
            # Exemple:
            # 1. PrÃ©traiter le texte
            # processed = self.preprocess(text)
            
            # 2. GÃ©nÃ©rer embeddings
            # embeddings = self.get_embeddings(processed)
            
            # 3. PrÃ©dire avec votre modÃ¨le
            # output = self.model(embeddings)
            # prediction = "DÃ‰PRESSION" if output > 0.5 else "NORMAL"
            # confidence = float(output)
            
            # Pour l'exemple, retournons un rÃ©sultat fictif
            prediction = "NORMAL"
            confidence = 0.75
            severity = "Aucune"
            reasoning = "Analyse basÃ©e sur GCN avec embeddings BERT"
            
            return {
                "prediction": prediction,
                "confidence": confidence,
                "severity": severity,
                "reasoning": reasoning
            }
            
        except Exception as e:
            logger.error(f"Erreur de prÃ©diction: {e}")
            raise
    
    # ========================================================================
    # MÃ‰THODE OPTIONNELLE: BATCH_PREDICT
    # ========================================================================
    
    def batch_predict(self, texts: List[str], **kwargs) -> List[Dict[str, Any]]:
        """
        PrÃ©diction batch (optionnel, mais recommandÃ© pour performance).
        
        Si non implÃ©mentÃ©, l'implÃ©mentation par dÃ©faut appelle predict()
        pour chaque texte.
        """
        # ImplÃ©mentation par dÃ©faut (peut Ãªtre optimisÃ©e)
        return [self.predict(text, **kwargs) for text in texts]
        
        # OU implÃ©mentation optimisÃ©e:
        # results = []
        # embeddings = self.batch_get_embeddings(texts)
        # outputs = self.model(embeddings)
        # for output in outputs:
        #     results.append({...})
        # return results
```

### 3. CrÃ©er __init__.py

CrÃ©er `app/services/votre_nom_modele/__init__.py` :

```python
"""
Votre modÃ¨le
"""
from .votre_nom_model import VotreNomModel

__all__ = ['VotreNomModel']
```

### 4. Ajouter les DÃ©pendances

CrÃ©er `app/services/votre_nom_modele/requirements.txt` :

```txt
# DÃ©pendances spÃ©cifiques Ã  votre modÃ¨le
torch>=2.0.0
torch-geometric>=2.3.0
transformers>=4.30.0
scikit-learn>=1.3.0
```

### 5. Enregistrer le ModÃ¨le

Modifier `app/main.py` pour enregistrer votre modÃ¨le :

```python
@app.on_event("startup")
async def startup_event():
    # ... code existant ...
    
    # Ajouter votre modÃ¨le
    try:
        from app.services.votre_nom_modele import VotreNomModel
        registry.register(VotreNomModel())
        logger.info("âœ“ Votre modÃ¨le enregistrÃ©")
    except Exception as e:
        logger.error(f"âœ— Erreur: {e}")
```

### 6. Installer et Tester

```bash
# Installer vos dÃ©pendances
pip install -r app/services/votre_nom_modele/requirements.txt

# Lancer l'API
uvicorn app.main:app --reload

# Tester votre modÃ¨le
curl http://localhost:8000/api/v1/models

curl -X POST "http://localhost:8000/api/v1/predict?model_name=votre_nom-gcn" \
  -H "Content-Type: application/json" \
  -d '{"text": "I feel sad"}'
```

---

## ðŸ“ Exemple Complet : ModÃ¨le GCN

Voici un exemple complet d'un modÃ¨le GCN :

```python
"""
ModÃ¨le GCN de Jean Dupont
"""
import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel
from typing import Dict, Any, List
from app.core.base_model import BaseMLModel
from app.utils.logger import setup_logger

logger = setup_logger(__name__)


class DupontGCNModel(BaseMLModel):
    """ModÃ¨le GCN avec embeddings BERT"""
    
    @property
    def model_name(self) -> str:
        return "dupont-gcn"
    
    @property
    def model_version(self) -> str:
        return "1.0.0"
    
    @property
    def author(self) -> str:
        return "Jean Dupont"
    
    @property
    def description(self) -> str:
        return "GCN avec BERT embeddings et attention mechanism"
    
    @property
    def tags(self) -> List[str]:
        return ["gcn", "bert", "attention", "graph-neural-network"]
    
    def __init__(self, model_path: str = "./models/dupont_gcn.pt"):
        """Initialise le modÃ¨le GCN"""
        try:
            # Charger BERT
            self.tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
            self.bert = AutoModel.from_pretrained("bert-base-uncased")
            
            # Charger le modÃ¨le GCN
            self.gcn_model = torch.load(model_path)
            self.gcn_model.eval()
            
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            self.bert.to(self.device)
            self.gcn_model.to(self.device)
            
            logger.info(f"âœ“ {self.model_name} initialisÃ© sur {self.device}")
            self._initialized = True
            
        except Exception as e:
            logger.error(f"âœ— Erreur d'initialisation: {e}")
            self._initialized = False
            raise
    
    def get_embeddings(self, text: str) -> torch.Tensor:
        """GÃ©nÃ¨re les embeddings BERT"""
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=512
        ).to(self.device)
        
        with torch.no_grad():
            outputs = self.bert(**inputs)
            embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] token
        
        return embeddings
    
    def predict(self, text: str, **kwargs) -> Dict[str, Any]:
        """PrÃ©dit avec le GCN"""
        if not self._initialized:
            raise RuntimeError(f"{self.model_name} non initialisÃ©")
        
        try:
            # 1. GÃ©nÃ©rer embeddings
            embeddings = self.get_embeddings(text)
            
            # 2. PrÃ©dire avec GCN
            with torch.no_grad():
                output = self.gcn_model(embeddings)
                probs = torch.softmax(output, dim=1)
                pred_class = torch.argmax(probs, dim=1).item()
                confidence = probs[0, pred_class].item()
            
            # 3. InterprÃ©ter
            prediction = "DÃ‰PRESSION" if pred_class == 1 else "NORMAL"
            
            # DÃ©terminer sÃ©vÃ©ritÃ©
            if prediction == "DÃ‰PRESSION":
                if confidence > 0.9:
                    severity = "Ã‰levÃ©e"
                elif confidence > 0.7:
                    severity = "Moyenne"
                else:
                    severity = "Faible"
            else:
                severity = "Aucune"
            
            return {
                "prediction": prediction,
                "confidence": float(confidence),
                "severity": severity,
                "reasoning": f"Analyse GCN avec confiance {confidence:.2%}"
            }
            
        except Exception as e:
            logger.error(f"Erreur de prÃ©diction: {e}")
            raise
```

---

## ðŸ§ª Tests

CrÃ©er `tests/test_votre_modele.py` :

```python
"""
Tests pour votre modÃ¨le
"""
import pytest
from app.services.votre_nom_modele import VotreNomModel


def test_model_initialization():
    """Test d'initialisation"""
    model = VotreNomModel()
    assert model.model_name == "votre_nom-gcn"
    assert model.model_version == "1.0.0"


def test_model_predict():
    """Test de prÃ©diction"""
    model = VotreNomModel()
    result = model.predict("I feel sad")
    
    assert "prediction" in result
    assert "confidence" in result
    assert "severity" in result
    assert result["prediction"] in ["DÃ‰PRESSION", "NORMAL"]
    assert 0 <= result["confidence"] <= 1


def test_model_batch_predict():
    """Test de prÃ©diction batch"""
    model = VotreNomModel()
    texts = ["I'm happy", "I feel sad"]
    results = model.batch_predict(texts)
    
    assert len(results) == 2
    for result in results:
        assert "prediction" in result
```

---

## ðŸ“‹ Checklist

Avant de push votre modÃ¨le :

- [ ] Dossier crÃ©Ã© : `app/services/votre_nom_modele/`
- [ ] Classe implÃ©mente `BaseMLModel`
- [ ] MÃ©thode `predict()` retourne le bon format
- [ ] `requirements.txt` avec vos dÃ©pendances
- [ ] ModÃ¨le enregistrÃ© dans `app/main.py`
- [ ] Tests Ã©crits et passent
- [ ] Documentation ajoutÃ©e (docstrings)
- [ ] Pas de secrets dans le code (clÃ©s API, etc.)

---

## ðŸ¤ Bonnes Pratiques

### Nommage

- **Nom du modÃ¨le** : `nom_equipe-type` (ex: `dupont-gcn`, `martin-lstm`)
- **Dossier** : `app/services/nom_equipe_type/`
- **Classe** : `NomEquipeTypeModel` (ex: `DupontGCNModel`)

### Performance

- ImplÃ©menter `batch_predict()` pour optimiser
- Utiliser `@torch.no_grad()` pour l'infÃ©rence
- Charger le modÃ¨le une seule fois (dans `__init__`)

### Erreurs

- Toujours logger les erreurs
- Retourner un rÃ©sultat mÃªme en cas d'erreur
- Ne pas faire crasher l'API

### Documentation

- Docstrings claires
- Expliquer les paramÃ¨tres
- Donner des exemples

---

## â“ FAQ

### Q: Mon modÃ¨le utilise PyTorch, un autre utilise TensorFlow. ProblÃ¨me ?

**R:** Non ! Chaque modÃ¨le a ses propres dÃ©pendances dans son `requirements.txt`.

### Q: Comment gÃ©rer les fichiers de modÃ¨le volumineux ?

**R:** 
1. Ne PAS les commit dans git
2. Les stocker ailleurs (Google Drive, S3)
3. TÃ©lÃ©charger au premier lancement
4. Ajouter au `.gitignore`

### Q: Puis-je utiliser des donnÃ©es externes ?

**R:** Oui, mais :
- Documenter la source
- Respecter les licences
- Ne pas commit les donnÃ©es volumineuses

### Q: Mon modÃ¨le est lent, que faire ?

**R:**
- ImplÃ©menter `batch_predict()` optimisÃ©
- Utiliser GPU si disponible
- Cacher les rÃ©sultats frÃ©quents
- Optimiser le preprocessing

---

## ðŸ“ž Support

- **Documentation** : Voir les autres docs dans `docs/`
- **Exemple** : Regarder `app/services/yansnet_llm/`
- **Issues** : CrÃ©er une issue GitHub
- **Questions** : Demander Ã  l'Ã©quipe

---

**Bon courage pour votre modÃ¨le ! ðŸš€**
