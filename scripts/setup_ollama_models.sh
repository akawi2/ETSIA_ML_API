#!/bin/bash
# Script pour t√©l√©charger les mod√®les Ollama n√©cessaires
# Usage: ./scripts/setup_ollama_models.sh

set -e

echo "üöÄ Configuration des mod√®les Ollama..."

# V√©rifier si Ollama est accessible
OLLAMA_URL="${OLLAMA_BASE_URL:-http://localhost:11434}"
echo "üì° V√©rification de la connexion √† Ollama ($OLLAMA_URL)..."

max_retries=30
retry_count=0
while ! curl -s "$OLLAMA_URL/api/tags" > /dev/null; do
    retry_count=$((retry_count + 1))
    if [ $retry_count -ge $max_retries ]; then
        echo "‚ùå Impossible de se connecter √† Ollama apr√®s $max_retries tentatives"
        exit 1
    fi
    echo "‚è≥ En attente d'Ollama... ($retry_count/$max_retries)"
    sleep 2
done

echo "‚úÖ Ollama est accessible"

# T√©l√©charger Qwen 2.5 1.5B pour la d√©tection de d√©pression
echo ""
echo "üì• T√©l√©chargement de Qwen 2.5 1.5B (mod√®le de d√©tection)..."
docker exec ollama-server ollama pull qwen2.5:1.5b

# T√©l√©charger Llama 3.2 3B pour la g√©n√©ration de contenu
echo ""
echo "üì• T√©l√©chargement de Llama 3.2 3B (g√©n√©ration de contenu)..."
docker exec ollama-server ollama pull llama3.2:3b

# T√©l√©charger Llama 3.2 1B pour le fallback
echo ""
echo "üì• T√©l√©chargement de Llama 3.2 1B (fallback)..."
docker exec ollama-server ollama pull llama3.2:1b

# V√©rifier les mod√®les install√©s
echo ""
echo "üìã Mod√®les Ollama install√©s:"
docker exec ollama-server ollama list

echo ""
echo "‚úÖ Configuration termin√©e!"
echo ""
echo "Mod√®les disponibles:"
echo "  - qwen2.5:1.5b    ‚Üí D√©tection de d√©pression (200-500ms)"
echo "  - llama3.2:3b     ‚Üí G√©n√©ration de contenu (5-15s)"
echo "  - llama3.2:1b     ‚Üí Fallback (2-5s)"
